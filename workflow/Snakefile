## Phoebe C. R. Parrish
## Berger Lab, FHCRC
## 2022-03-01
## updated 2023-07-18 by DJ Groso
## snakemake v7.1.0

import os
import sys
import re
import pandas as pd

## define config file
configfile: "config/config.yaml"

## config variables
base_filename = config["base_filename"]
pgRNA_counts_ref = config["pgRNA_counts_ref"]
bowtie_idx_dir = config["bowtie_idx_dir"]
input_dir = config["input_dir"]

## set up paths for output files
results_dir_dict = {"fastqc_dir": "results/fastqc/",
                    "fastq_trimmed_dir": "results/fastq_trimmed/",
                    "fastq_demuxed_dir": "results/fastq_demuxed/",
                    "sam_dir": "results/sam/",
                    "bam_dir": "results/bam/",
                    "bam_sorted_dir": "results/bam_sorted/",
                    "pgRNA_counts_dir": "results/pgRNA_counts/"}

## get FASTQ file names in input folder
fastq_list = []
for fname in os.listdir(input_dir):
    if "fastq" in fname:
        fastq_list.append(fname)
# print("fastq_list = ", fastq_list)
fastq_list.sort()
# print("sorted fastq_list = ", fastq_list)

## make lists  of fastq names and trim coordinates for
## each sequencing strategy
if len(fastq_list) == 3:
    ## leave fastq_list as is
    trim_coords_list = [[1, 20], [2, 21], [1, 6]]
elif len(fastq_list) == 2:
    ## add a duplicate fastq2 to the end of the list
    barcode_fastq = fastq_list[1]
    print("barcode_fastq =", barcode_fastq)
    fastq_list.append(barcode_fastq)
    trim_coords_list = [[2, 20], [2, 21], [161, 166]]
else: 
    sys.exit("There must be either 2 or 3 FASTQ files in the input folder.")
# print("fastq_list = ", fastq_list)
# print("trim_coords = ", trim_coords_list)

## set up a dictionary with keynames for each trimmed output fastq
read_to_fastq = {}
fastq_trim_coords = {}
fastq_trim_keys = ["gRNA1", "gRNA2", "barcode"]
for i in range(0, 3):
        key_name = fastq_trim_keys[i]
        ## assign fastq_name, trim_coords to each key
        read_to_fastq[key_name] = fastq_list[i]
        fastq_trim_coords[key_name] = trim_coords_list[i]
# print("fastq_trim_coords =", fastq_trim_coords)
# print("read_to_fastq =", read_to_fastq)

sample_list = []
barcode_ref_file = open(config["barcode_ref_file"], "r")

for line in barcode_ref_file:
    ## get sample names from idemp ref file
    sample = line.strip().split("\t")[1]
    sample_list.append(sample)
sample_list.sort()
barcode_ref_file.close()

rule all:
    input:
        ## rule trim_reads
        # I
        # expand(input_dir + "{fastq}", fastq = fastq_list),
        # O
        expand(results_dir_dict['fastq_trimmed_dir'] + base_filename + "_{read}_trimmed.fastq", read=fastq_trim_keys),
        
        ## rule demux_fastqs
        # I
        # expand(results_dir_dict['fastq_trimmed_dir'] + base_filename + "_{read}_trimmed.fastq", read=fastq_trim_keys),
        # O
        expand(results_dir_dict["fastq_demuxed_dir"] + base_filename + "_{dmx_read}_trimmed_{sample}.fastq.gz", dmx_read = ["gRNA1", "gRNA2"], sample = sample_list),
        
        ## rule: align_reads
        expand(results_dir_dict["sam_dir"] + base_filename + "_{dmx_read}_trimmed_{sample}_aligned.sam",
            dmx_read = ["gRNA1", "gRNA2"],
            sample = sample_list),
        
        ## rule: make_sorted_bams
        expand(results_dir_dict["bam_sorted_dir"] + base_filename + "_{dmx_read}_trimmed_{sample}_aligned_sorted.bam",
            dmx_read = ["gRNA1", "gRNA2"],
            sample = sample_list),
        
        ## rule: get_stats
        expand(results_dir_dict["bam_sorted_dir"] + "flagstat/" + base_filename + "_{dmx_read}_trimmed_{sample}_aligned_sorted_flagstat.txt",
            dmx_read = ["gRNA1", "gRNA2"],
            sample = sample_list),
        
        ## rule: count_pgRNAs
        expand(results_dir_dict["pgRNA_counts_dir"]+ "counts_{sample}.txt",
            sample = sample_list),
        
        ## rule: combine_counts
        results_dir_dict["pgRNA_counts_dir"] + base_filename + "_pgRNA_counts.txt"

rule trim_reads:
    input:
        lambda wildcards: input_dir + read_to_fastq[wildcards.read]
    output:
        results_dir_dict['fastq_trimmed_dir'] + base_filename + "_{read}_trimmed.fastq"
    conda:
        "envs/fastx_toolkit.yaml"
    params: 
        start = lambda wildcards: fastq_trim_coords[wildcards.read][0],
        end = lambda wildcards: fastq_trim_coords[wildcards.read][1]
    log:
        "workflow/logs/trim_reads/{read}.log"
    shell:
        "zcat {input} | fastx_trimmer -f {params.start} -l {params.end} -o {output} 2>{log}"


rule demux_fastqs:
    input:
        gRNA1 = results_dir_dict['fastq_trimmed_dir'] + base_filename + "_gRNA1_trimmed.fastq",
        gRNA2 = results_dir_dict['fastq_trimmed_dir'] + base_filename + "_gRNA2_trimmed.fastq",
        barcode = results_dir_dict['fastq_trimmed_dir'] + base_filename + "_barcode_trimmed.fastq",
    output:
        expand(results_dir_dict['fastq_demuxed_dir'] + base_filename + "_{dmx_read}_trimmed_{sample}.fastq.gz",
            dmx_read = ["gRNA1", "gRNA2"],
            sample = sample_list)
    params:
        idemp = config["idemp"],
        n_mismatch = 1,
        ref = config["barcode_ref_file"],
        out_dir = results_dir_dict['fastq_demuxed_dir'], ## can't have folder as output => make it a param instead
        bad_names = expand(results_dir_dict['fastq_demuxed_dir'] + base_filename + "_{dmx_read}_trimmed.fastq_{sample}.fastq.gz",
            dmx_read = ["gRNA1", "gRNA2"],
            sample = sample_list) ## to get rid of duplicate ".fastq" in default idemp output
    log:
        "workflow/logs/demux_fastqs/idemp.log"
    resources:
        mem = 98,
        time = 24,
        cpus_per_task = 16 ## must use Python underscores not Bash dashes
    shell:
        """
        {params.idemp} -b {params.ref} -n {params.n_mismatch} \
        -I1 {input.barcode} -R1 {input.gRNA1} -R2 {input.gRNA2} -o {params.out_dir} &> {log}

        ## convert wildcards to bash arrays
        declare -a arr1=({params.bad_names})
        declare -a arr2=({output})
        len=${{#arr1[@]}} ## get length of arrays
        ## loop through wildcard arrays and move to correctly-named file
        for ((i=0; i<$len; i++));
        do
            # echo "${{arr1[$i]}}"
            mv ${{arr1[$i]}} ${{arr2[$i]}}
        done
        """

rule align_reads:
    input:
        fastq = results_dir_dict['fastq_demuxed_dir'] + base_filename + "_{dmx_read}_trimmed_{sample}.fastq.gz"
    output:
        results_dir_dict['sam_dir'] + base_filename + "_{dmx_read}_trimmed_{sample}_aligned.sam"
    conda:
        "envs/bowtie.yaml"
    params:
        idx = bowtie_idx_dir + "pgPEN_{dmx_read}"
    resources:
        mem = 98,
        time = 24,
        cpus_per_task = 16 ## must use Python underscores not Bash dashes
    log:
        "workflow/logs/align_reads/{dmx_read}_{sample}.log"
    shell:
        "bowtie -q -v 1 --best --strata --all --sam -p 4 {params.idx} {input.fastq} {output} &> {log}"

rule make_sorted_bams:
    input:
        results_dir_dict['sam_dir'] + base_filename + "_{dmx_read}_trimmed_{sample}_aligned.sam"
    output:
        results_dir_dict['bam_sorted_dir'] + base_filename + "_{dmx_read}_trimmed_{sample}_aligned_sorted.bam"
    conda:
        "envs/samtools.yaml"
    params:
        unsorted_bam_dir = results_dir_dict['bam_dir'],
        unsorted_bam = base_filename + "_{dmx_read}_trimmed_{sample}_aligned.bam",
        tmp = results_dir_dict['bam_sorted_dir'] + "tmp_{dmx_read}_{sample}"
    resources:
        mem = 32,
        time = 24
    log:
        "workflow/logs/make_sorted_bams/{dmx_read}_{sample}.log"
    shell:
        """
        mkdir -p {params.unsorted_bam_dir} ## TO DO: write a fxn to make this dir if it doesn't exist

        samtools view -bS -o {params.unsorted_bam_dir}/{params.unsorted_bam} {input}

        samtools sort -O bam -n {params.unsorted_bam_dir}/{params.unsorted_bam} -T {params.tmp} -o {output} &>{log}
        """

rule get_stats:
    input:
        results_dir_dict['bam_sorted_dir'] + base_filename + "_{dmx_read}_trimmed_{sample}_aligned_sorted.bam"
    output:
        results_dir_dict['bam_sorted_dir'] + "flagstat/" + base_filename + "_{dmx_read}_trimmed_{sample}_aligned_sorted_flagstat.txt"
    conda:
        "envs/samtools.yaml"
    log:
        "workflow/logs/get_stats/{dmx_read}_{sample}.log"
    shell:
        "samtools flagstat {input} 2>{log} 1>{output}" 

rule count_pgRNAs:
    input:
        bam1 = results_dir_dict['bam_sorted_dir'] + base_filename + "_gRNA1_trimmed_{sample}_aligned_sorted.bam",
        bam2 = results_dir_dict['bam_sorted_dir'] + base_filename + "_gRNA2_trimmed_{sample}_aligned_sorted.bam"
    output:
        results_dir_dict['pgRNA_counts_dir'] + "counts_{sample}.txt"
    conda:
        "envs/counter_efficient.yaml"
    params:
        ref = config["pgRNA_counts_ref"], 
        n_chunks = config["n_chunks"], 
        out_dir = results_dir_dict['pgRNA_counts_dir'],
        script = "workflow/scripts/counter_efficient.R"
    resources:
        mem = 98,
        time = 24,
        cpus_per_task = 16 ## must use Python underscores not Bash dashes
    log:
        "workflow/logs/count_pgRNAs/{sample}.log"
    shell:
        "Rscript {params.script} {input.bam1} {input.bam2} {params.n_chunks} {params.ref} {params.out_dir} &> {log}"

rule combine_counts:
    input:
        expand(results_dir_dict['pgRNA_counts_dir'] + "counts_{sample}.txt",
            sample = sample_list)
    output:
        results_dir_dict['pgRNA_counts_dir'] + base_filename + "_pgRNA_counts.txt"
    conda:
        "envs/python.yaml"
    params:
        annot_file = config["pgRNA_counts_ref"], 
        in_dir = results_dir_dict['pgRNA_counts_dir'],
        script = "workflow/scripts/combine_counts.py"
    log:
        "workflow/logs/combine_counts/combine_counts.log"
    shell:
        "python {params.script} {params.annot_file} {params.in_dir} {output} &>{log}"
